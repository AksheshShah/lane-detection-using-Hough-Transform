{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 32-bit",
   "metadata": {
    "interpreter": {
     "hash": "441c5eeff9ab0672e42037296cd3db4d1ef6a6c2d424a2348d90fffefa6a0475"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# **MAE 598: Machine Learning for Engineers**\n",
    "# **Lane Detection**\n",
    "## Group Members\n",
    "### * Aksheshkumar Ajaykumar Shah - 1217506160\n",
    "### * Poojan Chetanbhai Makwana - 1217717124\n",
    "### * Sai Karthik Mysore Mouliswar - 1217135829\n",
    "### * Sharanya Parameshwar Hebbar - 1217410207 "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Step 1: Importing Important Libraries\n",
    "### * In this step we will be importing the important libraries that will be helping us ahead to develop the model by using thier built-in functions\n",
    "### * The libraries include OpenCV to process the video, Numpy to perform mathematical operations, Matplot library to plot figures."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "source": [
    "# **Step 2: Development of the helper functions.**\n",
    "### These helper functions are developed by using the built in functions of the above mentioned libraries. These helper functions will be called in our model to help us detect lanes on the video. The helper function do_canny performs operations like doing canny transformations of each frame we obtain from the video, the do_segment function is divinding the image in segments and determing the segment that is important to us, the houghs functions is used to apply hough tranformation to our frame and highligh the lane with green light, the calculate_coordinates functions id used to calculate the coordinates of the line that are supposed to be marked on our frames to show lane, calculate_line function works on finding the line from the coordinate we have developed from the previous function, Visualize_lines functions is used to visualize the hough lines on our frame in the video to show the lane."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_canny(frame):\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_RGB2GRAY)\n",
    "    blur = cv.GaussianBlur(gray, (5,5),0)\n",
    "    cann = cv.Canny(blur,50,150)\n",
    "    return cann\n",
    "\n",
    "\n",
    "def do_segment(canny):\n",
    "    height = canny.shape[0]\n",
    "    polygons = np.array([[(0,height),(800,height),(380,290)]])\n",
    "    mask = np.zeros_like(canny)\n",
    "    cv.fillPoly(mask,polygons,255)\n",
    "    segment = cv.bitwise_and(canny,mask)\n",
    "    return segment\n",
    "\n",
    "def houghs(segment):\n",
    "    hough = cv.HoughLinesP(segment,2,np.pi/180,100,np.array([]),minLineLength = 100, maxLineGap = 50)\n",
    "    return hough\n",
    "\n",
    "\n",
    "def calculate_coordinates(frame,par):\n",
    "    slope, intercept = par\n",
    "    y1 = frame.shape[0]\n",
    "    y2 = int(y1-150)\n",
    "    x1 = int((y1-intercept)/slope)\n",
    "    x2 = int ((y2-intercept)/slope)\n",
    "    coordinates = np.array([x1,y1,x2,y2])\n",
    "    return coordinates\n",
    "\n",
    "def calculate_lines(frame,hough):\n",
    "    left = []\n",
    "    right = []\n",
    "    for line in hough:\n",
    "        x1,y1,x2,y2 = line.reshape(4)\n",
    "        parameters = np.polyfit((x1,x2),(y1,y2),1)\n",
    "        slope = parameters[0]\n",
    "        y_int = parameters[1]\n",
    "        if slope<0:\n",
    "            left.append((slope,y_int))\n",
    "        else:\n",
    "            right.append((slope,y_int))\n",
    "        if right:\n",
    "            right_avg = np.average(right,axis=0)\n",
    "            right_line = calculate_coordinates(frame,right_avg)\n",
    "        if left:\n",
    "            left_avg = np.average(left,axis=0)\n",
    "            left_line = calculate_coordinates(frame, left_avg)\n",
    "    return np.array([left_line,right_line])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def visualize_lines(frame,lines):\n",
    "    lines_visualize = np.zeros_like(frame)\n",
    "    if lines is not None:\n",
    "        for x1,y1,x2,y2 in lines:\n",
    "            cv.line(lines_visualize,(x1,y1),(x2,y2),(0,255,0),5)\n",
    "    return lines_visualize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "# Step 3: Creating a Model\n",
    "## In this step we will be recalling the above developed helper functions in order to detect lane on the data. The video is first read using the openCV function VideoCapture and the it is split into frames per 10 milisecond. these frames are feed to canny edge detector in order for it to find the lane markings on the road. Later hough Transformatioon is used to plot the lane and the plotted lane is imposed on the normal frame."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(file_path):#input is in the form of video\n",
    "    cap = cv.VideoCapture(file_path)\n",
    "    while (cap.isOpened()):\n",
    "        ret,frame = cap.read() # frame if the current frame of the video and ret is the boolean value from getting the frame.\n",
    "        if ret:\n",
    "            canny = do_canny(frame)\n",
    "            cv.imshow(\"Canny Transformation\",canny)\n",
    "            segment = do_segment(canny)\n",
    "            hough = houghs(segment)\n",
    "            lines = calculate_lines(frame,hough)\n",
    "            lines_visualize = visualize_lines(frame, lines)\n",
    "            cv.imshow(\"Hough Transformation\",lines_visualize)\n",
    "            output = cv.addWeighted(frame,0.9,lines_visualize,1,1)\n",
    "            cv.imshow(\"Final Result\",output)\n",
    "# we will be taking frames in the intervals of 10 seconds each and the key q can be used to close the program anytime we want.\n",
    "            if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "    return output"
   ]
  },
  {
   "source": [
    "# **Step 4: Calling the model**\n",
    "## In this step we feed in the video input to our model for it to process the video and give us the desired output that is the lanes on the road."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'C:\\Users\\shaha\\Documents\\Arizona State University\\MAE 598 Machine Learning\\project\\input.mp4'\n",
    "Model(file_path)"
   ]
  }
 ]
}